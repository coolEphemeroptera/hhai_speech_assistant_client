
---

# 自动语音识别（ASR）接口文档


## 连接配置

### WebSocket URL

```plaintext
wss://<server_ip>:10095
```


## 消息格式

所有消息均采用JSON格式进行传输。

### 初始化ASR模型请求

**请求示例**:

```json
{
  "mode": "2pass",
  "chunk_size": [5, 10, 5],
  "chunk_interval": 10,
  "encoder_chunk_look_back": 4,
  "decoder_chunk_look_back": 0,
  "wav_name": "microphone",
  "hotwords": "{\"小米手机\":20}",
  "itn": true,
  "is_speaking": true
}
```

**请求参数说明**:

| 参数名                  | 类型          | 描述                                                                                                                                  |
|----------------------|--------------|-------------------------------------------------------------------------------------------------------------------------------------|
| `mode`               | `string`     | 识别模式，目前支持`2pass`模式。                                                                                                        |
| `chunk_size`         | `array[int]` | 每个识别阶段的块大小数组，例如 `[5, 10, 5]` 表示不同阶段的块大小。                                                                                        |
| `chunk_interval`     | `int`        | 块的时间间隔，单位为毫秒。                                                                                                                    |
| `encoder_chunk_look_back` | `int`        | 编码器块的回看参数。                                                                                                                         |
| `decoder_chunk_look_back` | `int`        | 解码器块的回看参数。                                                                                                                         |
| `wav_name`           | `string`     | 语音流的名称，通常为“microphone”。                                                                                                           |
| `hotwords`           | `string`     | 包含热词及其权重的JSON字符串，例如 `{"小米科技":20}`。                                                                                           |
| `itn`                | `bool`       | 是否执行文本归一化。`true`表示执行，`false`表示不执行。                                                                                             |
| `is_speaking`        | `bool`       | 是否开启语音识别。`true`表示开启，`false`表示关闭。                                                                                                 |

### 音频数据发送

ASR客户端通过WebSocket发送音频数据流到服务器进行识别。

**数据格式**: 音频数据以`int16`格式的字节数组发送，每次发送960个采样点的数据。

### 识别结果响应

ASR服务器返回识别的文本结果。根据模式不同，响应可能包括在线结果和离线结果。

**响应示例**:

```json
{
  "mode": "2pass-online",
  "text": "好吗"
}
```

```json
{
  "mode": "2pass-offline",
  "text": "你好吗",
}
```

**响应参数说明**:

| 参数名          | 类型           | 描述                                                                                                                                  |
|--------------|---------------|-------------------------------------------------------------------------------------------------------------------------------------|
| `mode`       | `string`       | 响应模式，可能的值有`2pass-online`和`2pass-offline`。                                                                                   |
| `text`       | `string`       | 识别出的文本。                                                                                                                        |

## 处理流程

1. **初始化WebSocket连接**: 客户端通过WebSocket连接到ASR服务器，并发送初始化请求，配置识别参数和热词。
2. **音频数据传输**: 客户端录制音频并按块传输到ASR服务器，服务器处理后返回识别结果。
3. **接收识别结果**: 客户端实时接收并处理识别结果，按需求进行文本显示或进一步处理。

## 错误处理

在发生错误时，客户端将输出错误信息，并尝试重新连接或终止程序。

---

这份文档详细描述了ASR客户端的连接配置、消息格式、请求与响应参数的结构，并概述了ASR客户端的处理流程。